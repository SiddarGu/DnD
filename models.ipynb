{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jsonl data\n",
    "def load_jsonl(input_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        data = [json.loads(line.strip()) for line in lines]\n",
    "    return data\n",
    "\n",
    "# Assume each JSON object has a 'text' field and a 'label' field\n",
    "train_data = load_jsonl('data/train.jsonl')\n",
    "val_data = load_jsonl('data/valid.jsonl')\n",
    "\n",
    "train_texts = [item['input'] for item in train_data]\n",
    "train_labels = [item['target'] for item in train_data]\n",
    "val_texts = [item['input'] for item in val_data]\n",
    "val_labels = [item['target'] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels from strings to integers\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Adjust the max_features and other parameters as needed\n",
    "\n",
    "# Fit the vectorizer on training data and transform training and validation texts\n",
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "val_features = vectorizer.transform(val_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 45.86%\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier\n",
    "lr_clf = LogisticRegression(max_iter=10000)  # Adjust the max_iter and other parameters as needed\n",
    "lr_clf.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Predict on validation set\n",
    "val_predictions_encoded = lr_clf.predict(val_features)\n",
    "\n",
    "# Decode the predictions back to original labels\n",
    "val_predictions = label_encoder.inverse_transform(val_predictions_encoded)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] == val_predictions[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "# Print accuracy percentage rounded to 2 decimal points\n",
    "print(\"Logistic regression accuracy: {:.2f}%\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 28.89%\n"
     ]
    }
   ],
   "source": [
    "# Train a Multinomial Naive Bayes classifier\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Predict on validation set\n",
    "val_predictions_encoded = nb_clf.predict(val_features)\n",
    "\n",
    "# Decode the predictions back to original labels\n",
    "val_predictions = label_encoder.inverse_transform(val_predictions_encoded)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] == val_predictions[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Naive Bayes accuracy: {:.2f}%\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 84.65%\n",
      "Calibrated SVM accuracy: 83.64%\n"
     ]
    }
   ],
   "source": [
    "# Train a Linear SVM classifier\n",
    "svm_clf = LinearSVC(max_iter=10000, random_state=42)  # You can adjust the max_iter and other parameters as needed\n",
    "svm_clf.fit(train_features, train_labels_encoded)\n",
    "\n",
    "calibrated_svc = CalibratedClassifierCV(svm_clf, cv=5)\n",
    "calibrated_svc.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Predict on validation set\n",
    "val_predictions_encoded = svm_clf.predict(val_features)\n",
    "calibrated_svc_predictions_encoded = calibrated_svc.predict(val_features)\n",
    "\n",
    "# Decode the predictions back to original labels\n",
    "val_predictions = label_encoder.inverse_transform(val_predictions_encoded)\n",
    "calibrated_svc_predictions = label_encoder.inverse_transform(calibrated_svc_predictions_encoded)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "cali_total = 0\n",
    "cali_correct = 0\n",
    "\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] == val_predictions[i]:\n",
    "        correct += 1\n",
    "    if val_labels[i] == calibrated_svc_predictions[i]:\n",
    "        cali_correct += 1\n",
    "    total += 1\n",
    "    cali_total += 1\n",
    "\n",
    "print(\"SVM accuracy: {:.2f}%\".format(correct / total * 100))\n",
    "print(\"Calibrated SVM accuracy: {:.2f}%\".format(cali_correct / cali_total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 78.99%\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, random_state=42)  # Adjust the n_estimators and other parameters as needed\n",
    "rf_clf.fit(train_features, train_labels_encoded)\n",
    "\n",
    "# Predict on validation set\n",
    "val_predictions_encoded = rf_clf.predict(val_features)\n",
    "\n",
    "# Decode the predictions back to original labels\n",
    "val_predictions = label_encoder.inverse_transform(val_predictions_encoded)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "for i in range(len(val_labels)):\n",
    "    if val_labels[i] == val_predictions[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Random Forest accuracy: {:.2f}%\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(sentence, vectorizer, classifier, label_encoder):\n",
    "    # Transform the sentence using the trained TF-IDF vectorizer\n",
    "    features = vectorizer.transform([sentence])\n",
    "    \n",
    "    # Predict the class using the trained classifier\n",
    "    prediction_encoded = classifier.predict(features)\n",
    "    \n",
    "    # Decode the prediction to the original label\n",
    "    prediction = label_encoder.inverse_transform(prediction_encoded)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# returns a dictionary of the probabilities of each label\n",
    "def predict_probability(sentence, vectorizer, classifier, label_encoder):\n",
    "    # Transform the sentence using the trained TF-IDF vectorizer\n",
    "    features = vectorizer.transform([sentence])\n",
    "    \n",
    "    # Predict the class probabilities using the trained classifier\n",
    "    probabilities = classifier.predict_proba(features)\n",
    "    \n",
    "    # Convert the probabilities to a dictionary keyed by the label names\n",
    "    label_probabilities = dict(zip(label_encoder.classes_, probabilities[0]))\n",
    "    \n",
    "    return label_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label for the sentence is: stealth\n",
      "The probabilities of each label are:\n",
      "acrobatics: 0.00\n",
      "arcana: 0.00\n",
      "athletics: 0.00\n",
      "charisma: 0.00\n",
      "deception: 0.00\n",
      "dexterity: 0.00\n",
      "hand: 0.00\n",
      "handling: 0.00\n",
      "history: 0.00\n",
      "insight: 0.00\n",
      "intelligence: 0.00\n",
      "intimidation: 0.00\n",
      "investigation: 0.00\n",
      "medicine: 0.00\n",
      "nature: 0.00\n",
      "perception: 0.47\n",
      "performance: 0.00\n",
      "persuasion: 0.00\n",
      "religion: 0.00\n",
      "stealth: 0.52\n",
      "strength: 0.00\n",
      "survival: 0.00\n",
      "wisdom: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "sentence = \"Also, everyone roll perception and stealth\"\n",
    "predicted_label = predict_label(sentence, vectorizer, svm_clf, label_encoder)\n",
    "print(f\"The predicted label for the sentence is: {predicted_label}\")\n",
    "\n",
    "prob_dist = predict_probability(sentence, vectorizer, calibrated_svc, label_encoder)\n",
    "print(\"The probabilities of each label are:\")\n",
    "for label, prob in prob_dist.items():\n",
    "    print(f\"{label}: {prob:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
